##Spark Day 1

Today we will explore the value of using the distributed computing framework Spark. 
In most cases, Python is not feasible for processing big data. And in terms of distributed
systems out there, Spark's in-memory primitives provide performance up to 
[100 times faster](https://amplab.cs.berkeley.edu/wp-content/uploads/2013/02/shark_sigmod2013.pdf)
than Hive and other Hadoop systems in performing distributed machine learning tasks. 

Toady we will get familiar with the Spark environment using the Python API, PySpark. We would
run things locally using PySpark and tomorrow we will move on running Spark jobs in EC2 instances
in the cloud.
