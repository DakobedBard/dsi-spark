{
 "metadata": {
  "name": "",
  "signature": "sha256:cd5f093f6e102c9f942af499cc71b1b9d373e8c2e9dbac288bbb8f0adf11f3bf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "import json \n",
      "import pickle as pkl\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "import pyspark as ps\n",
      "from pyspark.mllib.feature import HashingTF\n",
      "from pyspark.mllib.regression import LabeledPoint\n",
      "from pyspark.mllib.classification import NaiveBayes\n",
      "from collections import Counter\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenize(text):\n",
      "    PUNCTUATION = set(string.punctuation)\n",
      "    STOPWORDS = set(stopwords.words('english'))\n",
      "    STEMMER = PorterStemmer()\n",
      "    tokens = word_tokenize(text)\n",
      "    lowercased = [t.lower() for t in tokens]\n",
      "    no_punctuation = []\n",
      "    for word in lowercased:\n",
      "        punct_removed = ''.join([letter for letter in word if not letter in PUNCTUATION])\n",
      "        no_punctuation.append(punct_removed)\n",
      "    no_stopwords = [w for w in no_punctuation if not w in STOPWORDS]\n",
      "    stemmed = [STEMMER.stem(w) for w in no_stopwords]\n",
      "    return [w for w in stemmed if w]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_raw = sc.textFile('s3n://newsgroup/news.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_raw = data_raw.repartition(16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = data_raw.map(lambda line: json.loads(line))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_to_name = data.map(lambda line: (line['label'], line['label_name'])).distinct().collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_pared = data.map(lambda line: (line['label'], line['text']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_cleaned = data_pared.map(lambda (label, text): (label, tokenize(text)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "values_only = data_cleaned.values()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "flat_map_vals = values_only.flatMap(lambda x: x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab = flat_map_vals.distinct()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab_var = vocab.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_word_vec(word_lst):\n",
      "    word_counter = Counter(word_lst)\n",
      "    return [word_counter[v] if v in word_counter else 0 for v in vocab_var]\n",
      "    \n",
      "label_word_vec_rdd = data_cleaned.mapValues(get_word_vec)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_point_rdd = label_word_vec_rdd.map(lambda (label, text): LabeledPoint(label, text))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_point_rdd.setName('LabelFeatures').persist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "LabelFeatures PythonRDD[24] at RDD at PythonRDD.scala:43"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_hashed, test_hashed = label_point_rdd.randomSplit([0.7, 0.3])\n",
      "train_hashed.count() #9107"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "9213"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = NaiveBayes.train(train_hashed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prediction_and_labels = test_hashed.map(lambda point: (model.predict(point.features), point.label))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "correct = prediction_and_labels.filter(lambda (predicted, actual): predicted == actual)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy = correct.count() / float(test_hashed.count())\n",
      "print \"Classifier correctly predicted category \" + str(accuracy * 100) + \" percent of the time\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classifier correctly predicted category 87.1450696954 percent of the time\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.feature import Word2Vec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inp = sc.textFile('/Users/jeffreytang/Desktop/zipfian/spring2015/spark/data/text8_lines').map(lambda row: row.split(\" \"))\n",
      "word2vec = Word2Vec()\n",
      "model = word2vec.fit(inp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "synonyms = model.findSynonyms('china', 40)\n",
      "\n",
      "for word, cosine_distance in synonyms:\n",
      "    print(\"{}: {}\".format(word, cosine_distance))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "taiwan: 0.80058324337\n",
        "korea: 0.737741172314\n",
        "japan: 0.701800346375\n",
        "thailand: 0.70176589489\n",
        "siam: 0.691451728344\n",
        "guangdong: 0.682512640953\n",
        "tibet: 0.679593384266\n",
        "guangzhou: 0.673976421356\n",
        "mainland: 0.665425240993\n",
        "singapore: 0.660070717335\n",
        "shanghai: 0.64423340559\n",
        "taipei: 0.634433984756\n",
        "shenzhen: 0.628821909428\n",
        "xinjiang: 0.6255453825\n",
        "cambodia: 0.62504863739\n",
        "republic: 0.624424219131\n",
        "szechuan: 0.623910903931\n",
        "india: 0.61892157793\n",
        "laos: 0.615884661674\n",
        "mongolia: 0.615379810333\n",
        "ethiopia: 0.607740819454\n",
        "hong: 0.606998383999\n",
        "burma: 0.605756878853\n",
        "haiti: 0.602813780308\n",
        "philippines: 0.602536976337\n",
        "turkey: 0.599704146385\n",
        "matsu: 0.598631680012\n",
        "yuan: 0.595514237881\n",
        "nepal: 0.591737449169\n",
        "uzbekistan: 0.588676571846\n",
        "kong: 0.587439417839\n",
        "beijing: 0.581845581532\n",
        "malaysia: 0.580085933208\n",
        "manchuria: 0.575682520866\n",
        "russia: 0.571349024773\n",
        "tajikistan: 0.563312888145\n",
        "pakistan: 0.56185656786\n",
        "chongqing: 0.558681726456\n",
        "rhodesia: 0.558159530163\n",
        "kanuri: 0.556102573872\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.transform('general')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "DenseVector([0.1152, 0.0732, 0.0801, -0.1077, 0.0666, -0.3045, 0.0447, 0.1346, 0.0186, -0.1405, -0.1257, 0.0679, -0.4155, 0.1696, 0.2194, -0.0855, -0.3067, -0.017, 0.0727, 0.0746, -0.0412, -0.1972, -0.1795, 0.4205, 0.0085, 0.0724, 0.0013, 0.1039, 0.3258, 0.2427, -0.3734, -0.016, -0.1786, -0.0444, -0.0471, -0.1833, 0.1321, 0.0646, 0.2282, -0.3168, -0.4004, 0.0803, 0.1293, -0.1078, -0.3852, -0.0829, -0.1228, 0.2494, 0.0514, 0.3108, -0.1722, 0.0774, -0.0016, -0.0823, 0.1644, -0.0216, 0.2569, 0.1823, -0.2944, 0.0479, -0.2519, -0.0805, 0.0509, 0.1508, 0.2934, 0.1819, -0.2121, 0.0414, 0.0001, -0.4395, 0.0191, 0.0615, -0.2305, -0.2185, -0.3078, -0.1504, -0.2443, 0.3791, 0.0013, -0.1338, 0.3929, -0.1762, 0.0439, -0.1673, -0.0838, 0.3801, -0.126, -0.1562, -0.1462, -0.0846, -0.094, -0.3495, 0.2944, -0.1924, -0.1789, 0.2187, 0.2328, 0.3146, -0.1107, 0.2129])"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model._java_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "JavaObject id=o138"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}